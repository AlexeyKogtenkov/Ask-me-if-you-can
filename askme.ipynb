{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Парсеры и прочие функции обработки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def tolower(s):\n",
    "    for i in range(len(s)):\n",
    "        if s[i] >= 'A' and s[i] <= 'Z':\n",
    "            s = s[:i] + chr(ord(s[i]) - ord('A') + ord('a')) + s[i + 1:]\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def preparing_data(filename = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train.txt', fo=None, flag='babi'):\n",
    "    input = open(filename, 'r')\n",
    "    output = None\n",
    "    if fo == None:\n",
    "        output = open(filename[:-4] + '_prepared.txt', 'w')\n",
    "    else:\n",
    "        output = open(fo, 'w')\n",
    "    s = input.readline()\n",
    "    cur_text = \"\"\n",
    "    while len(s) > 0:\n",
    "        s = tolower(s)\n",
    "        s = s.replace('.', '')\n",
    "        s = s.replace(',', '')\n",
    "        s = s.replace('!', '')\n",
    "        if s.find('?') != -1:\n",
    "            s = s.split('?')\n",
    "            left = s[0].split()\n",
    "            if flag == 'babi':\n",
    "                left = s[0].split()[1:]\n",
    "            right = s[1].split()\n",
    "            for i in range(len(right)):\n",
    "                if len(right[i]) > 0 and '9' >= right[i][0] >= '0':\n",
    "                    right[i] = ''\n",
    "            output.write(cur_text + 'QUESTION\\n' + ' '.join(left) + ' EOF \\n' + 'ANSWER\\n' + ' '.join(right) + ' EOF \\n\\n')\n",
    "            if flag != 'babi':\n",
    "                cur_text = '';\n",
    "        else:\n",
    "            if flag == 'babi':\n",
    "                if s.split()[0] == '1':\n",
    "                    cur_text = \"\"\n",
    "                s = ' '.join(s.split()[1:]) + ' EOF \\n'\n",
    "            else:\n",
    "                s = ' '.join(s.split()[0:]) + ' EOF \\n'\n",
    "            if s == ' EOF \\n':\n",
    "                s = ''\n",
    "            cur_text += s\n",
    "        s = input.readline()\n",
    "    input.close()\n",
    "    output.close()\n",
    "\n",
    "\n",
    "def creating_dictionary(filename='tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_train_prepared.txt', foname=None):\n",
    "    ii = filename.rfind('/')\n",
    "    dictionary = None\n",
    "    if foname == None:\n",
    "        fo = filename[:ii + 1] + 'dict_' + filename[ii + 1:]\n",
    "        fo = fo.replace('_prepared.txt', '.txt')\n",
    "        dictionary = open(fo, 'w')\n",
    "    else:\n",
    "        dictionary = open(foname, 'w')\n",
    "    d = dict()\n",
    "    input = open(filename, 'r')\n",
    "    s = input.readline()\n",
    "    while len(s) > 0:\n",
    "        if len(s.split()) > 1:\n",
    "            words = s.split()\n",
    "            for word in words:\n",
    "                if not(word in d):\n",
    "                    d[word] = len(d)\n",
    "        s = input.readline()\n",
    "    for word in d:\n",
    "        print(word, d[word])\n",
    "        dictionary.write(str(d[word]) + ' ' + word + '\\n')\n",
    "    input.close()\n",
    "    dictionary.close()\n",
    "\n",
    "\n",
    "def load_dictionary(filename='tasks_1-20_v1-2/en-10k/dict_q0_14691112131415161718207102-55s59t.txt'):\n",
    "    input = open(filename, 'r')\n",
    "    d = dict()\n",
    "    s = input.readline()\n",
    "    while len(s) > 0:\n",
    "        s = s.split()\n",
    "        d[s[1]] = int(s[0])\n",
    "        s = input.readline()\n",
    "    #print(d)\n",
    "    print('Dict. length:', len(d))\n",
    "    input.close()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Пример обработки данных и создания по ним словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winona 76\n",
      "south 22\n",
      "fit 115\n",
      "many 132\n",
      "there 31\n",
      "she 47\n",
      "after 45\n",
      "blue 99\n",
      "go 120\n",
      "up 29\n",
      "john 6\n",
      "tired 118\n",
      "and 52\n",
      "fits 107\n",
      "sandra 13\n",
      "garden 14\n",
      "jason 127\n",
      "container 113\n",
      "put 35\n",
      "get 124\n",
      "following 50\n",
      "chest 109\n",
      "gave 139\n",
      "football 30\n",
      "mice 67\n",
      "longer 43\n",
      "julius 88\n",
      "passed 140\n",
      "is 10\n",
      "square 100\n",
      "travelled 17\n",
      "wolf 79\n",
      "before 64\n",
      "hallway 8\n",
      "chocolates 106\n",
      "how 131\n",
      "sumit 117\n",
      "this 59\n",
      "he 49\n",
      "yes 32\n",
      "lion 86\n",
      "two 138\n",
      "discarded 42\n",
      "will 119\n",
      "north 20\n",
      "pajamas 123\n",
      "bigger 110\n",
      "dropped 39\n",
      "gertrude 71\n",
      "did 122\n",
      "bathroom 4\n",
      "antoine 129\n",
      "bored 126\n",
      "west 24\n",
      "of 21\n",
      "none 136\n",
      "red 103\n",
      "daniel 11\n",
      "one 135\n",
      "morning 60\n",
      "greg 90\n",
      "fred 61\n",
      "down 36\n",
      "carrying 134\n",
      "park 62\n",
      "sheep 75\n",
      "in 26\n",
      "cat 80\n",
      "kitchen 19\n",
      "either 142\n",
      "apple 34\n",
      "yesterday 56\n",
      "above 96\n",
      "gray 93\n",
      "pink 97\n",
      "got 33\n",
      "that 46\n",
      "the 3\n",
      "bernhard 83\n",
      "green 84\n",
      "inside 108\n",
      "box 105\n",
      "they 53\n",
      "swan 89\n",
      "not 44\n",
      "school 58\n",
      "suitcase 112\n",
      "bedroom 18\n",
      "sphere 104\n",
      "evening 66\n",
      "where 9\n",
      "milk 41\n",
      "below 102\n",
      "picked 28\n",
      "hungry 130\n",
      "lily 81\n",
      "mouse 73\n",
      "objects 133\n",
      "what 23\n",
      "afterwards 48\n",
      "bill 54\n",
      "a 72\n",
      "right 101\n",
      "yellow 94\n",
      "maybe 144\n",
      "afraid 69\n",
      "or 143\n",
      "afternoon 65\n",
      "EOF 5\n",
      "three 141\n",
      "frog 82\n",
      "julie 57\n",
      "left 38\n",
      "office 15\n",
      "triangle 95\n",
      "mary 0\n",
      "yann 125\n",
      "chocolate 116\n",
      "does 114\n",
      "thirsty 128\n",
      "are 68\n",
      "why 121\n",
      "rectangle 98\n",
      "rhino 92\n",
      "east 25\n",
      "color 91\n",
      "was 63\n",
      "journeyed 16\n",
      "no 27\n",
      "grabbed 37\n",
      "jessica 78\n",
      "emily 77\n",
      "white 87\n",
      "handed 137\n",
      "brian 85\n",
      "took 40\n",
      "to 2\n",
      "cats 74\n",
      "moved 1\n",
      "then 51\n",
      "than 111\n",
      "cinema 55\n",
      "wolves 70\n",
      "went 7\n",
      "back 12\n"
     ]
    }
   ],
   "source": [
    "preparing_data('tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t.txt')\n",
    "creating_dictionary('tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Функция консольного интерфейса\n",
    "\n",
    "Осторожно, нужно вначале скомпилировать класс модели ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def main_func():\n",
    "    stage = -1\n",
    "    print('Hello! This is a program for \"ask me\" project.')\n",
    "    s = input()\n",
    "    s = s.split()\n",
    "    model = None\n",
    "    d = None\n",
    "    file_gen_answer = list()\n",
    "    file_gen_question = list()\n",
    "    file_gen_text = list()\n",
    "    while True:\n",
    "        if len(s) == 1 and s[0] == 'exit':\n",
    "            if model != None:\n",
    "                del model\n",
    "            return 0\n",
    "        elif (len(s) == 1 or len(s) == 2) and s[0] == 'help':\n",
    "            if len(s) == 1:\n",
    "                print('Commands: help, prepare, create, load, save, train, test.')\n",
    "                print('Print \"help <command>\" for details.')\n",
    "            elif s[1] == 'help':\n",
    "                print('\"help help\"?? You are really mad, man. :-)')\n",
    "            elif s[1] == 'create':\n",
    "                print('Command \"create\" is used for creating model.')\n",
    "                print('\"create model\" or \"create -m\" will start creating model, you have to follow instructions after it.')\n",
    "            elif s[1] == 'prepare':\n",
    "                print('Command \"prepare\" is used for preparing data and dictionary before training.')\n",
    "                print('\"prepare data <filename>\" will create a file with prepared data from file <filename>.')\n",
    "                print('\"prepare data <filename> <output>\" will create a file with prepared data from file <filename> with name <output>')\n",
    "                print('\"prepare babidata <filename>\" and \"prepare babidata <filename> <output>\" do the same things, '\n",
    "                      'but parser is specific for bAbI data. Note that every string in bAbI set starts with a number of string')\n",
    "                print('\"prepare dictionary <filename>\" will create a dictionary from file <filename>.'\n",
    "                      ' Note that this file must be with prepared data')\n",
    "                print('\"prepare dictionary <filename> <output>\" does the same, but dictionary will be written to file <output>')\n",
    "            elif s[1] == 'save':\n",
    "                print('Command \"save\" is used for saving models.')\n",
    "                print('\"save model <filename>\" or \"save -m <filename>\" will save your current model to file <filename>')\n",
    "            elif s[1] == 'load':\n",
    "                print('Command \"load\" is used for loading models and dictionaries.')\n",
    "                print('\"load model <name>\" or \"load -m <name>\" will load model with name <name>.')\n",
    "                print('\"load dictionary <filename>\" or \"load -d <filename>\" will load dictionary from file <filename>.')\n",
    "            elif s[1] == 'train':\n",
    "                print('Command \"train\" is used for training current model.')\n",
    "                print('\"train\" will start training model, you have to follow instructions after it.')\n",
    "            elif s[1] == 'test':\n",
    "                print('Command \"test\" is used for testing model and predicting.')\n",
    "                print('\"test\" will start testing, you have to follow instructions after it.')\n",
    "        elif len(s) == 3 and s[0] == 'load':\n",
    "            if (s[1] == 'model' or s[1] == '-m'):\n",
    "                info = open(s[2] + '.info', 'r')\n",
    "                NUM_SENTENCES, INPUT_SIZE, HIDDEN_SIZE, NUM_PASSES = map(int, info.readlines())\n",
    "                info.close()\n",
    "                model = Model(NUM_SENTENCES=NUM_SENTENCES,\n",
    "                              INPUT_SIZE=INPUT_SIZE,\n",
    "                              HIDDEN_SIZE=HIDDEN_SIZE,\n",
    "                              NUM_PASSES=NUM_PASSES)\n",
    "                model.restore(s[2])\n",
    "                print('Done!')\n",
    "            elif s[1] == 'dictionary' or s[1] == '-d':\n",
    "                d = load_dictionary(s[2])\n",
    "        elif len(s) == 3 and s[0] == 'save':\n",
    "            if (s[1] == 'model' or s[1] == '-m') and model != None:\n",
    "                model.save(s[2])\n",
    "        elif (len(s) == 3 or len(s) == 4) and s[0] == 'prepare':\n",
    "            if s[1] == 'data':\n",
    "                print('NOT BABI PARSER IS USED')\n",
    "                if len(s) == 3:\n",
    "                    preparing_data(s[2], flag='notbabi')\n",
    "                else:\n",
    "                    preparing_data(s[2], s[3], flag='notbabi')\n",
    "                print('Done!')\n",
    "            elif s[1] == 'babidata':\n",
    "                if len(s) == 3:\n",
    "                    preparing_data(s[2])\n",
    "                else:\n",
    "                    preparing_data(s[2], s[3])\n",
    "                print('Done!')\n",
    "            elif s[1] == 'dictionary':\n",
    "                if len(s) == 3:\n",
    "                    creating_dictionary(s[2])\n",
    "                else:\n",
    "                    creating_dictionary(s[2], s[3])\n",
    "        elif len(s) == 2 and s[0] == 'create':\n",
    "            if s[1] == 'model' or s[1] == '-m':\n",
    "                print('Please enter the following constants:\\n')\n",
    "                print('Maximum number of sentences: ', end='')\n",
    "                NUM_SENTENCES = int(input())\n",
    "                print('Max size of dictionary (you can skip this step by typing 0 if you already have loaded dictionary): ', end='')\n",
    "                INPUT_SIZE = int(input())\n",
    "                while (True):\n",
    "                    if INPUT_SIZE <= 0 and d != None:\n",
    "                        INPUT_SIZE = len(d)\n",
    "                        break\n",
    "                    if INPUT_SIZE > 0:\n",
    "                        break\n",
    "                    print('Wrong value. Please try again.')\n",
    "                    print('Max size of dictionary (you can skip this step by typing 0, but only if you already have loaded dictionary): ', end='')\n",
    "                    INPUT_SIZE = int(input())\n",
    "                print('Typical size of hidden layers (you can skip this step by typing 0): ', end='')\n",
    "                HIDDEN_SIZE = int(input())\n",
    "                if HIDDEN_SIZE <= 0:\n",
    "                    HIDDEN_SIZE = 100\n",
    "                print('Number of passes through data in network (you can skip this step by typing 0): ', end='')\n",
    "                NUM_PASSES = int(input())\n",
    "                if NUM_PASSES <= 0:\n",
    "                    NUM_PASSES = 5\n",
    "                print('Creating model. Please, wait...')\n",
    "                model = Model(NUM_SENTENCES=NUM_SENTENCES,\n",
    "                              INPUT_SIZE=INPUT_SIZE,\n",
    "                              HIDDEN_SIZE=HIDDEN_SIZE,\n",
    "                              NUM_PASSES=NUM_PASSES)\n",
    "                print('Done!')\n",
    "        elif len(s) == 1 and s[0] == 'test':\n",
    "            print('Please enter the following constants:\\n')\n",
    "            print('Batch size (you can skip this step by typing 0): ', end='')\n",
    "            batch_size = max(int(input()), 1)\n",
    "            print('Name of file with test data: ', end='')\n",
    "            filename = input().rstrip()\n",
    "            print('Output answers? (y/n): ', end='')\n",
    "            flag = input().rstrip()\n",
    "            if flag == 'y':\n",
    "                flag = 'predict_write'\n",
    "            else:\n",
    "                flag = 'predict'\n",
    "            print('Ends of string (zeros or EOF): ', end='')\n",
    "            end_type = input().rstrip()\n",
    "            model.predict(batch_size=batch_size, filename=filename, d=d, flag=flag, end_type=end_type)\n",
    "            print('Done!')\n",
    "        elif len(s) == 1 and s[0] == 'train':\n",
    "            print('Please enter the following constants:\\n')\n",
    "            print('Batch size: ', end='')\n",
    "            batch_size = max(int(input()), 1)\n",
    "            print('Name of file with train data: ', end='')\n",
    "            filename = input().rstrip()\n",
    "            print('Number of epochs: ', end='')\n",
    "            epochs = max(int(input()), 0)\n",
    "            print('End of string (zeros or EOF): ', end='')\n",
    "            end_type = input().rstrip()\n",
    "            print('Frequency of saving model (you can skip this step by typing 0): ', end='')\n",
    "            freq_saving = int(input())\n",
    "            if freq_saving <= 0:\n",
    "                freq_saving = 4\n",
    "            print('Training...')\n",
    "            model.learn(epochs=epochs, batch_size=batch_size, filename=filename, \n",
    "                        freq_saving=freq_saving, d=d, end_type=end_type)\n",
    "            print('Done!')\n",
    "        elif len(s) == 1 and s[0] == 'gen':\n",
    "            if len(file_gen_answer) == 0:\n",
    "                print('Please enter the filename.')\n",
    "                s = input().rstrip()\n",
    "                cur_text = ''\n",
    "                file_gen_answer = list()\n",
    "                file_gen_question = list()\n",
    "                file_gen_text = list()\n",
    "                fin = open(s, 'r')\n",
    "                s = fin.readline()\n",
    "                while len(s) > 0:\n",
    "                    if s == '\\n' and len(cur_text) > 0:\n",
    "                        cur_text = cur_text.split('QUESTION\\n')\n",
    "                        file_gen_text.append(cur_text[0].replace(' EOF', '.'))\n",
    "                        cur_text = cur_text[1].split('ANSWER\\n')\n",
    "                        file_gen_question.append(cur_text[0].replace(' EOF', '?'))\n",
    "                        file_gen_answer.append(cur_text[1].replace(' EOF', ''))\n",
    "                        cur_text = ''\n",
    "                    else:\n",
    "                        cur_text += s\n",
    "                    s = fin.readline()\n",
    "                fin.close()\n",
    "                print(\"\\n\", len(file_gen_text), \"examples\")\n",
    "            randn = random.randint(0, len(file_gen_text) - 1)\n",
    "            text = file_gen_text[randn].split('\\n')\n",
    "            for n_string in range(len(text)):\n",
    "                print(n_string, text[n_string])\n",
    "            print(file_gen_question[randn].rstrip(), end=' ')\n",
    "            print('Answer:', file_gen_answer[randn])\n",
    "            s = input().rstrip()\n",
    "            while s != 'e' and s != 'close' and s != 'exit' and s != 'c':\n",
    "                if s == 'a' or s == 'accept':\n",
    "                    output = open('tmp.tmp', 'w')\n",
    "                    output.write(tolower(file_gen_text[randn]).replace('.', ' EOF').rstrip() + '\\nQUESTION\\n' + \n",
    "                                 tolower(file_gen_question[randn]).replace('?', ' EOF').rstrip() + '\\nANSWER\\n' + \n",
    "                                 tolower(file_gen_answer[randn]).rstrip() + ' EOF\\n')\n",
    "                    output.close()\n",
    "                    print()\n",
    "                    if model != None:\n",
    "                        model.predict(batch_size=1, filename='tmp.tmp', d=d, flag='predict_write')\n",
    "                        print()\n",
    "                        #randn = random.randint(0, len(file_gen_text) - 1)\n",
    "                    else:\n",
    "                        print('ERROR: no model loaded.')\n",
    "                elif s == 'chq':\n",
    "                    s = input()\n",
    "                    file_gen_question[randn] = s\n",
    "                elif s == 'cha':\n",
    "                    s = input().rstrip()\n",
    "                    file_gen_answer[randn] = s\n",
    "                elif len(s.split()) == 2:\n",
    "                    s = s.split()\n",
    "                    pos = max(0, int(s[1]))\n",
    "                    pos = min(len(text), pos)\n",
    "                    if s[0] == 'rm' and pos < len(text):\n",
    "                        text.pop(pos)\n",
    "                    elif s[0] == 'rm':\n",
    "                        print('Index out of range')\n",
    "                    elif (s[0] == 'add' or s[0] == 'ins') and pos <= len(text):\n",
    "                        s = input().rstrip()\n",
    "                        text.insert(pos, s)\n",
    "                    elif s[0] == 'add' or s[0] == 'ins':\n",
    "                        print('Index out of range')\n",
    "                    else:\n",
    "                        print('Unknown command')\n",
    "                    file_gen_text[randn] = '\\n'.join(text) + '\\n'\n",
    "                elif s == 'd' or s == 'p':\n",
    "                    randn = random.randint(0, len(file_gen_text) - 1)\n",
    "                    text = file_gen_text[randn].split('\\n')\n",
    "                for n_string in range(len(text)):\n",
    "                    print(n_string, text[n_string])\n",
    "                print(file_gen_question[randn].rstrip(), end=' ')\n",
    "                print('Answer:', file_gen_answer[randn])\n",
    "                s = input().rstrip()\n",
    "        else:\n",
    "            print('Unknown command.')\n",
    "        s = input().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! This is a program for \"ask me\" project.\n",
      "load -m tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_7\n",
      "Done!\n",
      "exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Класс модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, \n",
    "                 NUM_SENTENCES = 58,\n",
    "                 INPUT_SIZE = 100,\n",
    "                 HIDDEN_SIZE = 100,\n",
    "                 NUM_PASSES = 5):\n",
    "        self.graph = tf.Graph()\n",
    "        self.NUM_SENTENCES = NUM_SENTENCES\n",
    "        self.INPUT_SIZE = INPUT_SIZE\n",
    "        self.HIDDEN_SIZE = HIDDEN_SIZE\n",
    "        self.NUM_PASSES = NUM_PASSES\n",
    "        with self.graph.as_default():\n",
    "            self.train_inputs = tf.placeholder(tf.float32, shape=[None, None, INPUT_SIZE], name='i') #batch_size; max_words; input_size\n",
    "            self.train_question = tf.placeholder(tf.float32, shape=[None, None, INPUT_SIZE], name='q') #batch_size; len_question; input_size\n",
    "            self.lookup = tf.placeholder(tf.float32, shape=[None, NUM_SENTENCES, None]) #batch_size; num_sentences; max_words\n",
    "            with tf.variable_scope(\"question_module\"):\n",
    "                _, q_state = tf.nn.dynamic_rnn(tf.contrib.rnn.GRUCell(num_units=HIDDEN_SIZE), \n",
    "                                               self.train_question, dtype = tf.float32)\n",
    "            with tf.variable_scope(\"input_module\"):\n",
    "                input_output, _ = tf.nn.dynamic_rnn(tf.contrib.rnn.GRUCell(num_units=HIDDEN_SIZE), \n",
    "                                                   self.train_inputs, dtype = tf.float32)\n",
    "                input_output = tf.matmul(self.lookup, input_output)\n",
    "\n",
    "            BATCH_SIZE = tf.shape(self.train_inputs)[0]\n",
    "            with tf.variable_scope(\"attention_mechanism\"):\n",
    "                m_cell = tf.contrib.rnn.GRUCell(HIDDEN_SIZE)\n",
    "                am_cell = tf.contrib.rnn.GRUCell(num_units=HIDDEN_SIZE) \n",
    "                m_state = m_cell.zero_state(BATCH_SIZE, tf.float32)\n",
    "                cur_ep = tf.Variable(tf.zeros(HIDDEN_SIZE))\n",
    "                cur_m = q_state\n",
    "                for i in range(NUM_PASSES):\n",
    "                    am_state = am_cell.zero_state(BATCH_SIZE, tf.float32)\n",
    "                    prev_state = am_cell.zero_state(BATCH_SIZE, tf.float32)\n",
    "                    for t in range(NUM_SENTENCES):\n",
    "                        c = input_output[:, t, :]\n",
    "                        z = tf.concat([c, cur_m, q_state, c * q_state, c * cur_m, \n",
    "                                       tf.abs(c - q_state), tf.abs(c - cur_m)], 1)\n",
    "\n",
    "                        g1 = tf.tanh(tf.layers.dense(z, HIDDEN_SIZE, name='dense1', reuse=bool(t + i)))\n",
    "                        g = tf.sigmoid(tf.layers.dense(g1, HIDDEN_SIZE, name='dense2', reuse=bool(t + i)))\n",
    "                        if t > 0 or i > 0:\n",
    "                            tf.get_variable_scope().reuse_variables()\n",
    "                        _, am_state = am_cell(c, am_state)\n",
    "                        am_state = tf.add(g * am_state, (1-g)*prev_state)\n",
    "                        prev_state = am_state\n",
    "                    cur_ep = am_state\n",
    "                    _, m_state = m_cell(cur_ep, m_state)\n",
    "\n",
    "            W_a = tf.Variable(tf.truncated_normal([INPUT_SIZE, HIDDEN_SIZE]))\n",
    "            loss = 0\n",
    "            self.train_answer = tf.placeholder(tf.int32, shape=[None, INPUT_SIZE], name='a')\n",
    "            with tf.variable_scope(\"answer_module\"):\n",
    "                a_cell = tf.contrib.rnn.GRUCell(HIDDEN_SIZE)\n",
    "                a_state = m_state\n",
    "                prev_predict = a_cell.zero_state(BATCH_SIZE, tf.float32)\n",
    "                _, a_state = a_cell(tf.concat([prev_predict, q_state], 1), a_state)\n",
    "                self.prev_predict = (tf.transpose(tf.matmul(W_a, a_state, transpose_b=True)))\n",
    "                loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(self.train_answer, self.prev_predict))\n",
    "            self.accuracy = tf.losses.mean_squared_error(self.train_answer, tf.nn.softmax(self.prev_predict))\n",
    "            self.optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "            init = tf.global_variables_initializer()\n",
    "            self.saver = tf.train.Saver()\n",
    "        self.session = tf.Session(graph=self.graph)\n",
    "        self.session.run(init)\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.session.close()\n",
    "    \n",
    "    def restore(self, filename=None):\n",
    "        if filename == None:\n",
    "            print(\"Requirement: filename\")\n",
    "            return 1\n",
    "        self.saver.restore(self.session, filename)\n",
    "        return 0\n",
    "    \n",
    "    def learn(self, epochs=10, batch_size=100, filename=None, freq_saving=4, d=None, flag='learn', end_type='zeros'):\n",
    "        if d == None:\n",
    "            print('Requirement: dictionary')\n",
    "            return 1\n",
    "        if filename == None:\n",
    "            print('Requirement: filename')\n",
    "            return 2\n",
    "        freq_saving = max(freq_saving, 1)\n",
    "        BATCH_SIZE = batch_size\n",
    "        questions_txt = [''] * BATCH_SIZE\n",
    "        train_text_txt = [''] * BATCH_SIZE\n",
    "        max_words = 0\n",
    "        question_len = 0\n",
    "        train_answers = numpy.zeros((BATCH_SIZE, self.INPUT_SIZE), dtype=numpy.float32)\n",
    "        cur_s = 0\n",
    "        input = None\n",
    "        for ep in range(epochs):\n",
    "            c = 0\n",
    "            if flag == 'learn':\n",
    "                print(\"Epoch: \", ep)\n",
    "            s = ''\n",
    "            input = open(filename, 'r')\n",
    "            s = input.readline()\n",
    "            stage = 't'\n",
    "            cur_text = \"\"\n",
    "            average_loss = 0\n",
    "            while len(s) > 0:\n",
    "                v = s.split()\n",
    "                if len(v) > 1 and stage != 'a':\n",
    "                    cur_text += s\n",
    "                elif len(v) > 0 and v[0] == \"QUESTION\":\n",
    "                    stage = 'q'\n",
    "                    train_text_txt[cur_s] = cur_text\n",
    "                    max_words = max(max_words, len(cur_text.split()))\n",
    "                    cur_text = \"\"\n",
    "                elif len(v) > 0 and v[0] == \"ANSWER\":\n",
    "                    stage = 'a'\n",
    "                    questions_txt[cur_s] = cur_text\n",
    "                    question_len = max(question_len, len(cur_text.split()))\n",
    "                    cur_text = \"\"\n",
    "                elif stage == 'a' and len(v) > 0:\n",
    "                    cur_text = s.split()\n",
    "                    train_answers[cur_s, d[cur_text[0]]] = 1\n",
    "                    cur_text = \"\"\n",
    "                    stage = 't'\n",
    "                    cur_s += 1\n",
    "                if cur_s == BATCH_SIZE:\n",
    "                    train_text = numpy.zeros((BATCH_SIZE, max_words, self.INPUT_SIZE), dtype=numpy.float32)\n",
    "                    train_questions = numpy.zeros((BATCH_SIZE, question_len, self.INPUT_SIZE), dtype=numpy.float32)\n",
    "                    lookups = numpy.zeros((BATCH_SIZE, self.NUM_SENTENCES, max_words), dtype=numpy.float16)\n",
    "                    for _ in range(BATCH_SIZE):\n",
    "                        current_text = train_text_txt[_].split()\n",
    "                        lookup_ind = 0\n",
    "                        lkps = 0\n",
    "                        for __ in range(len(current_text)):\n",
    "                            train_text[_, __, d[current_text[__]]] = 1\n",
    "                            if current_text[__] == 'EOF':\n",
    "                                lookups[_, lookup_ind, lkps] = 1\n",
    "                                lookup_ind += 1\n",
    "                            lkps += 1\n",
    "                        current_question = questions_txt[_].split()\n",
    "                        for __ in range(len(current_question)):\n",
    "                            train_questions[_, __, d[current_question[__]]] = 1\n",
    "                        if end_type == 'EOF':\n",
    "                            for __ in range(len(current_question), question_len):\n",
    "                                train_questions[_, __, d['EOF']] = 1\n",
    "                    feed_dict = {self.train_inputs: train_text, self.train_question: train_questions, \n",
    "                                     self.train_answer: train_answers, self.lookup: lookups}\n",
    "                    if flag == 'learn':\n",
    "                        answer = self.prev_predict.eval(session=self.session, feed_dict=feed_dict)\n",
    "                        for i in range(BATCH_SIZE):\n",
    "                            average_loss += int(numpy.argmax(answer[i]) == numpy.argmax(train_answers[i]))\n",
    "                        _, loss_val = self.session.run([self.optimizer, self.accuracy], feed_dict=feed_dict)\n",
    "                    else:\n",
    "                        answer = self.prev_predict.eval(session=self.session, feed_dict=feed_dict)\n",
    "                        for i in range(BATCH_SIZE):\n",
    "                            average_loss += int(numpy.argmax(answer[i]) == numpy.argmax(train_answers[i]))\n",
    "                            if flag == 'predict_write':\n",
    "                                ind_ans = numpy.argmax(answer[i])\n",
    "                                for word in d:\n",
    "                                    if d[word] == ind_ans:\n",
    "                                        print(\"NN answer:\", word, end = ', ')\n",
    "                                ind_true_ans = numpy.argmax(train_answers[i])\n",
    "                                for word in d:\n",
    "                                    if d[word] == ind_true_ans:\n",
    "                                        print(\" real answer:\", word)\n",
    "                    cur_s = 0\n",
    "                    train_answers = numpy.zeros((BATCH_SIZE, self.INPUT_SIZE), dtype=numpy.int32)\n",
    "                    max_words = 0\n",
    "                    question_len = 0\n",
    "                    c += BATCH_SIZE\n",
    "                s = input.readline()\n",
    "            print('Average accuracy:', average_loss / c)\n",
    "            input.close()\n",
    "            if flag == 'learn' and ep % freq_saving == 0:\n",
    "                self.save(filename + '_' + str(ep // freq_saving))\n",
    "                #self.saver.save(self.session, filename + '_' + str(ep // freq_saving))\n",
    "        return 0\n",
    "    \n",
    "    def predict(self, batch_size=100, filename=None, d=None, flag='predict', end_type='zeros'):\n",
    "        return self.learn(epochs=1, batch_size=batch_size, filename=filename, d=d, flag=flag)\n",
    "    \n",
    "    def save(self, filename=None):\n",
    "        if filename == None:\n",
    "            print('Requirement: file to save')\n",
    "            return 1\n",
    "        self.saver.save(self.session, filename)\n",
    "        output = open(filename + '.info', 'w')\n",
    "        output.write(str(self.NUM_SENTENCES) + '\\n' + str(self.INPUT_SIZE) \n",
    "                     + '\\n' + str(self.HIDDEN_SIZE) + '\\n' + str(self.NUM_PASSES))\n",
    "        output.close()\n",
    "        print('The last save is in file ' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Примеры работы с функциями и классом модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = load_dictionary('tasks_1-20_v1-2/en-10k/dict_q0_14691112131415161718207102-55s59t.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(INPUT_SIZE=len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.restore('tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_3.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN answer: wolf,  real answer: wolf\n",
      "NN answer: mouse,  real answer: yes\n",
      "NN answer: kitchen,  real answer: kitchen\n",
      "NN answer: bathroom,  real answer: kitchen\n",
      "NN answer: white,  real answer: white\n",
      "NN answer: gray,  real answer: yellow\n",
      "NN answer: yes,  real answer: no\n",
      "NN answer: yes,  real answer: yes\n",
      "NN answer: garden,  real answer: garden\n",
      "NN answer: bedroom,  real answer: bedroom\n",
      "NN answer: kitchen,  real answer: garden\n",
      "NN answer: kitchen,  real answer: bedroom\n",
      "NN answer: garden,  real answer: garden\n",
      "NN answer: bored,  real answer: park\n",
      "NN answer: gray,  real answer: gray\n",
      "NN answer: yellow,  real answer: yellow\n",
      "NN answer: office,  real answer: office\n",
      "NN answer: none,  real answer: none\n",
      "NN answer: none,  real answer: none\n",
      "NN answer: none,  real answer: two\n",
      "NN answer: one,  real answer: one\n",
      "NN answer: bedroom,  real answer: kitchen\n",
      "NN answer: kitchen,  real answer: kitchen\n",
      "NN answer: bedroom,  real answer: kitchen\n",
      "NN answer: kitchen,  real answer: kitchen\n",
      "NN answer: bathroom,  real answer: garden\n",
      "NN answer: bathroom,  real answer: garden\n",
      "NN answer: bedroom,  real answer: bedroom\n",
      "Average loss: 0.5714285714285714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(batch_size=1, filename='tasks_1-20_v1-2/en-10k/test.txt', d=d, flag='predict_write')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Average loss: 0.8947029393370857\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_0\n",
      "Epoch:  1\n",
      "Average loss: 0.9201875\n",
      "Epoch:  2\n",
      "Average loss: 0.9268125\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_1\n",
      "Epoch:  3\n",
      "Average loss: 0.93209375\n",
      "Epoch:  4\n",
      "Average loss: 0.9349875\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_2\n",
      "Epoch:  5\n",
      "Average loss: 0.93914375\n",
      "Epoch:  6\n",
      "Average loss: 0.94131875\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_3\n",
      "Epoch:  7\n",
      "Average loss: 0.94436875\n",
      "Epoch:  8\n",
      "Average loss: 0.94620625\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_4\n",
      "Epoch:  9\n",
      "Average loss: 0.94739375\n",
      "Epoch:  10\n",
      "Average loss: 0.95061875\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_5\n",
      "Epoch:  11\n",
      "Average loss: 0.95284375\n",
      "Epoch:  12\n",
      "Average loss: 0.9548030018761726\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_6\n",
      "Epoch:  13\n",
      "Average loss: 0.95546875\n",
      "Epoch:  14\n",
      "Average loss: 0.9561125\n",
      "The last save is in file tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt_7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(filename='tasks_1-20_v1-2/en-10k/q0_14691112131415161718207102-55s59t_prepared.txt', \n",
    "            d=d, epochs=15, freq_saving=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
